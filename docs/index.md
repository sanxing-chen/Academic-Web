---
title: Sanxing Chen - NLP
lang: en-US
sidebar: false
---
<link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC" rel="stylesheet">

<!-- # <div><p style="font-variant: small-caps; display: inline;">Sanxing Chen</p></div> -->
<h3></h3>
<div><h1 style='background: unset; color: #012169;'>Sanxing</h1> <h1>Chen</h1>

</div>
<!-- <p style="font-family:'Noto Serif SC', serif; display: inline;">陈三星</p> -->

<style type="text/css"> 
p:nth-child(6) .icon.outbound,
p:nth-child(7) .icon.outbound
{
  display: none;
}
a {
  display: inline-block;
}
</style>

<img src="./img/sketch.png" alt="img" id="myimg" style="float:right;transition: width 0.5s;opacity: 0.8;">

## Bio

I am a third-year PhD student at Duke University, advised by [Bhuwan Dhingra](https://users.cs.duke.edu/~bdhingra/) and previously [Sam Wiseman](https://swiseman.github.io).
I am a member of [DukeNLP](https://nlplab.cs.duke.edu/).
My research investigates how LLMs explore, reason, and plan in dynamic environments.
<!-- I research, through a language processing lens, how to help computers to learn, think, and communicate in the way human beings do.
Humans learn language through brief interactions with the world at an early developmental stage, and then it becomes the [conduit](https://en.wikipedia.org/wiki/Conduit_metaphor) that transmits all kinds of knowledge between people.
In contrast, current most advanced learning systems *learn* language from trillions of words in plain text.
I'm thus interested in efficient situated learning, especially in an interactive environment. -->

I did my master's work at the University of Virginia, where I was a member of the [ILP Lab](https://uvanlp.org/) working with [Yangfeng Ji](http://yangfengji.net).
I've also spent time at [Google DeepMind](https://deepmind.google/), Microsoft Advertising, and Microsoft Research ([Beijing](https://www.microsoft.com/en-us/research/group/data-knowledge-intelligence/) and [Redmond](https://www.microsoft.com/en-us/research/group/deep-learning-group/)).

*I was lucky to have great mentors and be involved in research during my undergrad study. If you're a Duke undergrad and feel like I can be of some help to your research career, feel free to email me!*

## News  :tada:
- **[Jun 03, 2024]** I started my internship at [Google DeepMind](https://deepmind.google/) NYC!
- **[Mar 28, 2023]** We released our follow-up work of ⚾️ HittER on [arXiv](https://arxiv.org/abs/2303.15682)!

<!-- 

- **[Jul 22, 2022]** I collected a list of papers I found interesting at [NAACL 2022](https://sanxing.notion.site/NAACL-2022-5168912ed6724d73b3beb995040280d5).
- **[Nov 01, 2021]** HittER paper is accpeted to EMNLP 2021 (oral presentation), check out our [paper](https://aclanthology.org/2021.emnlp-main.812/) and [code](https://github.com/microsoft/HittER)!
- **[Jun 27, 2021]** I'm moving to the Greater Seattle Area to join Microsoft as an applied scientist!
- **[Jan 06, 2021]** I'll be joining [MSR](https://www.microsoft.com/en-us/research/group/deep-learning-group/) as a research intern this spring!
- **[Dec 14, 2020]** All Ph.D. applications have been sent out, wish me luck!
- **[Nov 01, 2020]** I'll be volunteering at [EMNLP 2020](https://2020.emnlp.org/), and presenting at [COLING 2020](https://coling2020.org) virtually!
- **[Jun 12, 2020]** I'll be attending [AKBC 2020](https://www.akbc.ws/2020/), [ACL 2020](https://acl2020.org/) and [ICML 2020](https://icml.cc/Conferences/2020) virtually!
- **[Apr 24, 2020]** I'll be attending [ICLR 2020](https://iclr.cc) virtually!
- **[Jan 19, 2020]** I'll be with Microsoft Ads and [MSR](https://www.microsoft.com/en-us/research/group/deep-learning-group/) this summer!
- **[Dec 21, 2019]** I'm actively seeking R&D internship opportunities for summer 2020!
- **[Dec 10, 2019]** We submitted one paper to ACL 2020!
- **[Mar 28, 2019]** Got accepted to MSCS@[UMass](https://umass.edu)!
- **[Feb 27, 2019]** I'm going to rejoin MSRA in April, excited to see my old friends there!
- **[Feb 21, 2019]** Got accepted to MSCS@[UVa](http://virginia.edu)!
- **[Dec 16, 2018]** All MS/Ph.D. applications sent out!

## Experience

<experience>
<template #company>Microsoft Bing Ads</template>
<template #title>Applied Scientist</template>
<template #location>Bellevue, United States</template>
<template #date>Jul 2021 - Now</template>
</experience>

<experience>
<template #company>Microsoft Research</template>
<template #title>Research Intern</template>
<template #location>Home office, United States</template>
<template #date>Mar 2021 - June 2021</template>
<template #work>Large-scale knowledge graph encoding with <a href="https://sites.google.com/site/hcheng2site">Hao Cheng</a> and <a href="https://sites.google.com/view/buptxiaodong/home">Xiaodong Liu</a></template>
</experience>
<experience>
<template #company>Bing Ads & Microsoft Research</template>
<template #title>Data Scientist Intern</template>
<template #location>Home office, United States</template>
<template #date>May 2020 - Aug 2020</template>
<template #work>Relational learning and NLP with <a href="https://sites.google.com/view/buptxiaodong/home">Xiaodong Liu</a> and <a href="https://www.linkedin.com/in/jian-jiao-82897810">Jian Jiao</a></template>
</experience>
<experience>
<template #company>Microsoft Research Asia</template>
<template #title>Intern</template>
<template #location>Beijing, China</template>
<template #date>Mar 2019 - Jun 2019</template>
<template #work><a href="bert-time.pdf" target="_blank">Time expression recognition</a> with <a href="https://www.microsoft.com/en-us/research/people/guow/" target="_blank">Guoxin Wang</a> and <a href="https://www.microsoft.com/en-us/research/people/borjekar/" target="_blank">Börje Karlsson</a></template>
</experience>
<experience>
<template #company>Microsoft Research Asia</template>
<template #title>Intern</template>
<template #location>Beijing, China</template>
<template #date>Feb 2018 - Sep 2018</template>
<template #work><a href="https://github.com/Microsoft/Recognizers-Text" target="_blank">Generic types entity recognition</a> with <a href="https://www.microsoft.com/en-us/research/people/borjekar/" target="_blank">Börje Karlsson</a></template>
</experience>
-->

## Publications [[Scholar]](https://scholar.google.com/citations?user=YtxKsUMAAAAJ)

<paper arxiv="https://arxiv.org/abs/2410.14651" code="https://github.com/sanxing-chen/adv-fake">
<template #title>Real-time Fake News from Adversarial Feedback</template>
<template #authors><strong>Sanxing Chen</strong>, Yukun Huang, Bhuwan Dhingra</template>
<template #venue>Preprint, 2024</template>
<template #abs>

::: tip Abstract
We show that existing evaluations for fake news detection based on conventional sources, such as claims on fact-checking websites, result in high accuracies over time for LLM-based detectors -- even after their knowledge cutoffs. This suggests that recent popular fake news from such sources can be easily detected due to pre-training and retrieval corpus contamination or increasingly salient shallow patterns. Instead, we argue that a proper fake news detection dataset should test a model's ability to reason factually about the current world by retrieving and reading related evidence. To this end, we develop a novel pipeline that leverages natural language feedback from a RAG-based detector to iteratively modify real-time news into deceptive fake news that challenges LLMs. Our iterative rewrite decreases the binary classification ROC-AUC by an absolute 17.5 percent for a strong RAG-based GPT-4o detector. Our experiments reveal the important role of RAG in both detecting and generating fake news, as retrieval-free LLM detectors are vulnerable to unseen events and adversarial attacks, while feedback from RAG detection helps discover more deceitful patterns in fake news.
:::

</template>
<template #bib>

``` tex
@article{chen2024realtime,
  title  = {Real-time Fake News from Adversarial Feedback},
  author = {Sanxing Chen and Yukun Huang and Bhuwan Dhingra},
  year   = {2024},
  journal={arXiv preprint arXiv:2410.14651},
}
```

</template>
</paper>

<paper arxiv="https://arxiv.org/abs/2410.14675" code="https://github.com/kkkevinkkkkk/situated_faithfulness">
<template #title>Enhancing Large Language Models' Situated Faithfulness to External Contexts</template>
<template #authors>Yukun Huang, <strong>Sanxing Chen</strong>, Hongyi Cai, Bhuwan Dhingra</template>
<template #venue>In ICLR, 2024 (Spotlight)</template>
<template #abs>

::: tip Abstract
Large Language Models (LLMs) are often augmented with external information as contexts, but this external information can sometimes be inaccurate or even intentionally misleading. We argue that robust LLMs should demonstrate situated faithfulness, dynamically calibrating their trust in external information based on their confidence in the internal knowledge and the external context. To benchmark this capability, we evaluate LLMs across several QA datasets, including a newly created dataset called RedditQA featuring in-the-wild incorrect contexts sourced from Reddit posts. We show that when provided with both correct and incorrect contexts, both open-source and proprietary models tend to overly rely on external information, regardless of its factual accuracy. To enhance situated faithfulness, we propose two approaches: Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning (RCR). SCR enables models to self-access the confidence of external information relative to their own internal knowledge to produce the most accurate answer. RCR, in contrast, extracts explicit confidence signals from the LLM and determines the final answer using predefined rules. Our results show that for LLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR outperforms RCR, achieving improvements of up to 24.2% over a direct input augmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR outperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct Preference Optimization (CR-DPO) method improves performance on both seen and unseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. In addition to quantitative results, we offer insights into the relative strengths of SCR and RCR. Our findings highlight promising avenues for improving situated faithfulness in LLMs. The data and code are released.
:::

</template>
<template #bib>

``` tex
@article{Huang2024enhancing,
  title  = {Enhancing Large Language Models' Situated Faithfulness to External Contexts},
  author = {Yukun Huang and Sanxing Chen and Hongyi Cai and Bhuwan Dhingra},
  journal={arXiv preprint arXiv:2410.14675},
  year={2024}
}
```

</template>
</paper>

<paper arxiv="https://arxiv.org/abs/2404.09911" code="https://github.com/sanxing-chen/ChatShop">
<template #title>ChatShop: Interactive Information Seeking with Language Agents</template>
<template #authors><strong>Sanxing Chen</strong>, Sam Wiseman, Bhuwan Dhingra</template>
<template #venue>Preprint, 2024</template>
<template #abs>

::: tip Abstract
The desire and ability to seek new information strategically are fundamental to human learning but often overlooked in current language agent evaluation. We analyze a popular web shopping task designed to test language agents' ability to perform strategic exploration and discover that it can be reformulated and solved as a single-turn retrieval task without the need for interactive information seeking. This finding encourages us to rethink realistic constraints on information access that would necessitate strategic information seeking. We then redesign the task to introduce a notion of task ambiguity and the role of a shopper, serving as a dynamic party with whom the agent strategically interacts in an open-ended conversation to make informed decisions. Our experiments demonstrate that the proposed task can effectively evaluate the agent's ability to explore and gradually accumulate information through multi-turn interactions. Additionally, we show that large language model-simulated shoppers serve as a good proxy for real human shoppers, revealing similar error patterns in agents.
:::

</template>
<template #bib>

``` tex
@article{chen2024chatshop,
  title={ChatShop: Interactive Information Seeking with Language Agents},
  author={Chen, Sanxing and Wiseman, Sam and Dhingra, Bhuwan},
  journal={arXiv preprint arXiv:2404.09911},
  year={2024}
}
```

</template>
</paper>

<paper arxiv="https://arxiv.org/abs/2404.09911" code="https://github.com/ybai-nlp/CItruS">
<template #title>CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling</template>
<template #authors>Yu Bai, Xiyuan Zou, Heyan Huang, <strong>Sanxing Chen</strong>, Marc-Antoine Rondeau, Yang Gao, Jackie CK Cheung</template>
<template #venue>In EMNLP, 2024 (Main) </template>
<template #abs>

::: tip Abstract
Long sequence modeling has gained broad interest as large language models (LLMs) continue to advance. Recent research has identified that a large portion of hidden states within the key-value caches of Transformer models can be discarded (also termed evicted) withoutaffecting the perplexity performance in generating long sequences. However, we show that these methods, despite preserving perplexity performance, often drop information that is important for solving downstream tasks, a problem which we call information neglect. To address this issue, we introduce Chunked Instruction-aware State Eviction (CItruS), a novel modeling technique that integrates the attention preferences useful for a downstream task into the eviction process of hidden states. In addition, we design a method for chunked sequence processing to further improve efficiency. Our training-free method exhibits superior performance on long sequence comprehension and retrieval tasks over several strong baselines under the same memory budget, while preserving language modeling perplexity.
:::

</template>
<template #bib>

``` tex
@inproceedings{bai-etal-2024-citrus,
    title = "{CI}tru{S}: Chunked Instruction-aware State Eviction for Long Sequence Modeling",
    author = "Bai, Yu  and
      Zou, Xiyuan  and
      Huang, Heyan  and
      Chen, Sanxing  and
      Rondeau, Marc-Antoine  and
      Gao, Yang  and
      Cheung, Jackie CK",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.338/",
    doi = "10.18653/v1/2024.emnlp-main.338",
    pages = "5908--5930"
}
```

</template>
</paper>


<paper paper="https://aclanthology.org/2024.findings-naacl.164/" arxiv="https://arxiv.org/abs/2405.10861"  code="https://github.com/rickardstureborg/tailor-cgo">
<template #title>Tailoring Vaccine Messaging with Common-Ground Opinions</template>
<template #authors>Rickard Stureborg, <strong>Sanxing Chen</strong>, Ruoyu Xie, Aayushi Patel, Christopher Li, Chloe Qinyu Zhu, Tingnan Hu, Jun Yang, Bhuwan Dhingra</template>
<template #venue>In NAACL'2024 (Findings)</template>
<template #abs>

::: tip Abstract
One way to personalize chatbot interactions is by establishing common ground with the intended reader. A domain where establishing mutual understanding could be particularly impactful is vaccine concerns and misinformation. Vaccine interventions are forms of messaging which aim to answer concerns expressed about vaccination. Tailoring responses in this domain is difficult, since opinions often have seemingly little ideological overlap. We define the task of tailoring vaccine interventions to a Common-Ground Opinion (CGO). Tailoring responses to a CGO involves meaningfully improving the answer by relating it to an opinion or belief the reader holds. In this paper we introduce TAILOR-CGO, a dataset for evaluating how well responses are tailored to provided CGOs. We benchmark several major LLMs on this task; finding GPT-4-Turbo performs significantly better than others. We also build automatic evaluation metrics, including an efficient and accurate BERT model that outperforms finetuned LLMs, investigate how to successfully tailor vaccine messaging to CGOs, and provide actionable recommendations from this investigation.
:::

</template>
<template #bib>

``` tex
@misc{stureborg2024tailoring,
      title={Tailoring Vaccine Messaging with Common-Ground Opinions}, 
      author={Rickard Stureborg and Sanxing Chen and Ruoyu Xie and Aayushi Patel and Christopher Li and Chloe Qinyu Zhu and Tingnan Hu and Jun Yang and Bhuwan Dhingra},
      year={2024},
      eprint={2405.10861},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

</template>
</paper>

<paper arxiv="https://arxiv.org/abs/2303.15682" code="https://github.com/microsoft/HittER">
<template #title>Pre-training Transformers for Knowledge Graph Completion</template>
<template #authors><strong>Sanxing Chen</strong>, Hao Cheng, Xiaodong Liu, Jian Jiao, Yangfeng Ji, Jianfeng Gao</template>
<template #venue>Preprint, 2023</template>
<template #abs>

::: tip Abstract
Learning transferable representation of knowledge graphs (KGs) is challenging due to the heterogeneous, multi-relational nature of graph structures. Inspired by Transformer-based pretrained language models' success on learning transferable representation for texts, we introduce a novel inductive KG representation model (iHT) for KG completion by large-scale pre-training. iHT consists of a entity encoder (e.g., BERT) and a neighbor-aware relational scoring function both parameterized by Transformers. We first pre-train iHT on a large KG dataset, Wikidata5M. Our approach achieves new state-of-the-art results on matched evaluations, with a relative improvement of more than 25% in mean reciprocal rank over previous SOTA models. When further fine-tuned on smaller KGs with either entity and relational shifts, pre-trained iHT representations are shown to be transferable, significantly improving the performance on FB15K-237 and WN18RR.
:::

</template>
<template #bib>

``` tex
@misc{chen2023pretraining,
      title={Pre-training Transformers for Knowledge Graph Completion}, 
      author={Sanxing Chen and Hao Cheng and Xiaodong Liu and Jian Jiao and Yangfeng Ji and Jianfeng Gao},
      year={2023},
      eprint={2303.15682},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

</template>
</paper>


<paper paper="https://aclanthology.org/2021.emnlp-main.812/" arxiv="https://arxiv.org/abs/2008.12813" code="https://github.com/microsoft/HittER">
<template #title>⚾️ HittER: Hierarchical Transformers for Knowledge Graph Embeddings</template>
<template #authors><strong>Sanxing Chen</strong>, Xiaodong Liu, Jianfeng Gao, Jian Jiao, Ruofei Zhang, Yangfeng Ji</template>
<template #venue>In EMNLP'2021 (Oral)</template>
<template #abs>

::: tip Abstract
This paper examines the challenging problem of learning representations of entities and relations in a complex multi-relational knowledge graph. We propose HittER, a **Hi**erarchical **T**ransformer model **t**o jointly learn **E**ntity-relation composition and **R**elational contextualization based on a source entity’s neighborhood. Our proposed model consists of two different Transformer blocks: the bottom block extracts features of each entity-relation pair in the local neighborhood of the source entity and the top block aggregates the relational information from outputs of the bottom block. We further design a masked entity prediction task to balance information from the relational context and the source entity itself. Experimental results show that HittER achieves new state-of-the-art results on multiple link prediction datasets. We additionally propose a simple approach to integrate HittER into BERT and demonstrate its effectiveness on two Freebase factoid question answering datasets.
:::

</template>
<template #bib>

``` tex
@inproceedings{chen-etal-2021-hitter,
    title = "{H}itt{ER}: Hierarchical Transformers for Knowledge Graph Embeddings",
    author = "Chen, Sanxing  and
      Liu, Xiaodong  and
      Gao, Jianfeng  and
      Jiao, Jian  and
      Zhang, Ruofei  and
      Ji, Yangfeng",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.812",
    pages = "10395--10407",
}
```

</template>
</paper>

<paper paper="https://doi.org/10.18130/v3-mhyd-et41">
<template #title>Contextualizing Language Understanding with Graph-based Knowledge Representations</template>
<template #authors><strong>Sanxing Chen</strong></template>
<template #venue>Master's thesis, The University of Virginia, 2020</template>
<template #abs>

::: tip Abstract
Language understanding requires not only linguistic knowledge but also relies on knowledge that is external to textual symbols.
A vast amount of knowledge is stored in the form of graph-structured data in many application domains.
Despite a growing interest in developing knowledge-driven approaches in the community, how to build powerful representations of graph-structured knowledge and effectively incorporate them into language understanding models remains a challenging problem in natural language processing research.

This thesis explores the direction of contextualizing language understanding with graph-based knowledge representations.
I first demonstrate the challenges of building meaningful interactions between language representations and domain-specific knowledge representations in the task of cross-domain Text-to-SQL semantic parsing.
By citing this example, I point out the idea of fostering multiple connections between the two representations in their different levels of abstraction and utilize the idea to substantially improve two graph neural network-based semantic parsers.
To implement this idea in a more general form to benefits more language understanding tasks, I propose a new knowledge graph representation model that shares a similar Transformer architecture design with prevalent language models.
In the task of factoid question answering, I show that the proposed knowledge representations can be effectively integrated into state-of-the-art pre-trained language models via a simple cross-modality attention mechanism.
:::

</template>
<template #bib>

``` tex
@mastersthesis{chen2020contextualizing,
	title = {Contextualizing Language Understanding with Graph-based Knowledge Representations},
	school = {The University of Virginia},
	author = {Chen, Sanxing},
	year = {2020},
	langid = {english}
}
```

</template>
</paper>

<paper paper="https://www.aclweb.org/anthology/2020.coling-main.260" arxiv="https://arxiv.org/abs/2009.14809" code="https://github.com/sanxing-chen/linking-tale">
<template #title>A Tale of Two Linkings: Dynamically Gating between Schema Linking and Structural Linking for Text-to-SQL Parsing</template>
<template #authors><strong>Sanxing Chen</strong>, Aidan San, Xiaodong Liu, Yangfeng Ji</template>
<template #venue>In COLING'2020 (Oral)</template>
<template #abs>

::: tip Abstract
In Text-to-SQL semantic parsing, selecting the correct entities (tables and columns) to output is both crucial and challenging; the parser is required to connect the natural language (NL) question and the current SQL prediction with the structured world, *i.e.*, the database. We formulate two linking processes to address this challenge: *schema linking* which links explicit NL mentions to the database and *structural linking* which links the entities in the output SQL with their structural relationships in the database schema. Intuitively, the effects of these two linking processes change based on the entity being generated, thus we propose to dynamically choose between them using a gating mechanism. Integrating the proposed method with two graph neural network based semantic parsers together with BERT representations demonstrates substantial gains in parsing accuracy on the challenging Spider dataset. Analyses show that our method helps to enhance the structure of the model output when generating complicated SQL queries and offers explainable predictions.
:::

</template>
<template #bib>

``` tex
@inproceedings{chen2020tale,
    title = "A Tale of Two Linkings: Dynamically Gating between Schema Linking and Structural Linking for Text-to-{SQL} Parsing",
    author = "Chen, Sanxing  and
      San, Aidan  and
      Liu, Xiaodong  and
      Ji, Yangfeng",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.coling-main.260",
    pages = "2900--2912"
}
```

</template>
</paper>

## Service

- Reviewer: COLING'2020, NAACL'2021, ACL'2021, EMNLP'2021, NLPCC'2021, CoLM'2024, COLING'2024, ARR (regularly)
- Volunteer: ACL'2020, EMNLP'2020

## Misc

<!-- - My name is pronounced as "sǣnɕə̄ŋ". -->
- I am originally from [Quanzhou](https://en.wikipedia.org/wiki/Quanzhou), China. It was one of the world's largest and most cosmopolitan seaports and now a [World Heritage Site](https://whc.unesco.org/en/list/1561). (Interestingly, UVA is also a [World Heritage Site](https://whc.unesco.org/en/list/442).)
- I started playing the violin when I was seven.
- I enjoy photography and traveling.

<ImageGallery />

## Contact

:email: sxing [dot] xyz [at] outlook [dot] com

:bird: @sanxing_chen

:camera: [Instagram](https://www.instagram.com/sxing.xyz/)